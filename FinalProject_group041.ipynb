{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that PIDs will be scraped from the public submission, but student names will be included.)\n",
    "\n",
    "* [] YES - make available\n",
    "* [X] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we sought to find out the position groups in the NFL whose performance were most responsive to monetary investment. To do this, we gathered data from various websites regarding team positional spending and position group performance, and normalized all of the data to allow us to be able to better compare between years and position groups. We used this information to figure out the correlation between positional spending and their performance, and ran tests to compare correlations to explore possible significant differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Brandon Tsui\n",
    "- Joseph Li\n",
    "- Vicki Chen\n",
    "- Vincent Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A14630205\n",
    "- A14961114\n",
    "- A15536177\n",
    "- A15492589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which NFL position groups are most responsive to being improved, via increased monetary investment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As football enthusiasts, we are always searching for ways to improve our team through free agency. We've had our fair number of dissapointments seeing our team invest tons of money into one player, yet having that same player preform worse than a lower paid player in the same position. With our project, we want to analyze data to see which NFL position group is actually worth more monetary investment. This is important to us because we want to see our favorite team spend money that will actually improve the team.\n",
    "\n",
    "Our background references here give us a rough estimate of what we might expect with field experts and analyst's opinions. Our first two references give a ranking of the most important positions to fill in any football team, and our third reference gives us the highest, median, and lowest paid players at those positions. We looked at each chart and saw that some of the names in the median and lowest paid player charts in each position, based on our knowledge of football, actually preform better than some of the highest paid players. In addition, throughout the article the experts point out notable high preforming players that are paid outside of the highest paid charts(3). Of course, we would love to back our knowledge up with tangable data and actually see if that is the truth or just our personal bias as sports fans.\n",
    "\n",
    "The last refence, gives prior work that has already been done with NFL offensive investment by position trends. Though this study was done 5 years ago, we see that the expert used data to conclude that their was a positive correlation between offensive improvement and monetary spending, but not much correlation between spending and improvement in each offensive position group (4). As a group, we are curious in seeing how that same study looks today in the NFL and also on the defensive side of the field. We also want to expand on his study, seeing how monetary investment affects improvement in offensive postions like fullbacks that was not included in the study.\n",
    "\n",
    "References (include links):\n",
    "\n",
    "- 1) https://bleacherreport.com/articles/1237955-power-ranking-every-player-position-in-the-nfl?fbclid=IwAR3h1sHvCl-en9kQstCFf6D8PYyt1Eh79B5pOHv9nbL94OIShkOYrU2BGYg#slide3\n",
    "- 2) http://www.nfl.com/news/story/0ap3000000503855/article/ranking-each-positions-importance-from-quarterback-to-returner?fbclid=IwAR3FYhBO9Ij-tv9OXoLQh0A1Q4nwjjdeiqB4oe4igFmUvm3-FzdFxcSORfI\n",
    "- 3) https://bleacherreport.com/articles/1563549-breaking-down-the-money-at-every-nfl-position#slide1\n",
    "- 4) http://insidethepylon.com/nfl/front-office/2015/12/21/nfl-offensive-investment-by-position-trends/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis of our project is that we want to see which position groups are worth a bigger investment. Our thought is that there may be a difference in the correlation between spending and performance across the various position groups that compose an NFL team. Essentially we do not believe that, given the same level of investment, each position group will expereince the same degree of improvement in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Name: NFL Team Spending by Position, 2016-2019 <br>\n",
    "Link: https://overthecap.com/positional-spending/ <br>\n",
    "Number of observations: 32 observations per year * 4 years = 128 observations\n",
    "\n",
    "This is a table recording how much NFL teams have spent per position group per year over the last four NFL seasons. We use this as the source for our independent variable: monetary investment by the team.\n",
    "\n",
    "Dataset Name: Player Performance by Position, 2016-2019 <br>\n",
    "Links: \n",
    "- https://www.footballoutsiders.com/stats/nfl/qb/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/qb/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/qb/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/qb/2016\n",
    "- https://www.footballoutsiders.com/stats/nfl/rb/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/rb/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/rb/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/rb/2016\n",
    "- https://www.footballoutsiders.com/stats/nfl/wr/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/wr/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/wr/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/wr/2016\n",
    "- https://www.footballoutsiders.com/stats/nfl/te/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/te/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/te/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/te/2016\n",
    "- https://www.footballoutsiders.com/stats/nfl/offensive-line/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/offensive-line/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/offensive-line/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/offensive-line/2016\n",
    "- https://www.footballoutsiders.com/stats/nfl/defensive-line/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/defensive-line/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/defensive-line/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/defensive-line/2016\n",
    "- https://www.footballoutsiders.com/stats/nfl/team-defense/2019\n",
    "- https://www.footballoutsiders.com/stats/nfl/team-defense/2018\n",
    "- https://www.footballoutsiders.com/stats/nfl/team-defense/2017\n",
    "- https://www.footballoutsiders.com/stats/nfl/team-defense/2016<br> \n",
    "\n",
    "Number of observations (total): over 1600 (we considered an entire team defense as one observation)\n",
    "\n",
    "We aggregated the data from all of these links to form our player performance dataset. Different position groups are measured by different statistics, but the nature of our project is such that we only have to compare statistics within the same position group over multiple years.\n",
    "\n",
    "We selected the relevant performance metrics for each position group, standardized by year, and grouped by team. We also normalized the team spending by position group so that we could account for salary cap increases and inflation. Then, we joined this data together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering: Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for tranlating team name to 2-3 letter observations\n",
    "team_initial = {'Packers': 'GB', 'Buccaneers': 'TB', 'Chargers': 'LAC', 'Redskins' : 'WAS', 'Bengals': 'CIN', 'Raiders':\n",
    "               'OAK', 'Browns': 'CLE', '49ers': 'SF', 'Cowboys': 'DAL', 'Saints': 'NO','Titans':\n",
    "               'TEN','Colts': 'IND', 'Giants': 'NYG' , 'Vikings': 'MIN', 'Rams': 'LAR',\n",
    "               'Lions': 'DET', 'Chiefs': 'KC', 'Seahawks': 'SEA', 'Falcons': 'ATL', 'Eagles':'PHI',\n",
    "               'Patriots': 'NE', 'Jets': 'NYJ', 'Steelers': 'PIT', 'Texans': \"HOU\", 'Bears': 'CHI'\n",
    "               , 'Cardinals': 'ARI', 'Jaguars': 'JAX', 'Panthers': 'CAR', 'Bills': 'BUF'\n",
    "               ,'Ravens': 'BAL', 'Broncos': 'DEN','Dolphins': 'MIA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting team spending by year\n",
    "def get_spending_data_by_year(team_spending_url, year):\n",
    "    spending_page = requests.get(team_spending_url)\n",
    "    spending_html = BeautifulSoup(spending_page.text)\n",
    "    spending_div = spending_html.find('div', {'id': 'y' + str(year)})\n",
    "    spending_table = spending_div.find('table', class_='sortable')\n",
    "    \n",
    "    list_teams, list_qb, list_rb, list_wr, list_te, list_ol, list_dl, list_lb, list_s, list_cb = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    for row in spending_table.find('tbody').findAll('tr'):\n",
    "        cells = row.findAll('td')\n",
    "\n",
    "        if len(cells) < 10:\n",
    "            continue\n",
    "\n",
    "        list_teams.append(cells[0].find('a').text) #team name\n",
    "        list_qb.append(cells[1].text) #QB spending\n",
    "        list_rb.append(cells[2].text) #RB spending\n",
    "        list_wr.append(cells[3].text) #WR spending\n",
    "        list_te.append(cells[4].text) #TE spending\n",
    "        list_ol.append(cells[5].text) #OL spending\n",
    "        list_dl.append(cells[7].text) #DL spending\n",
    "        list_lb.append(cells[8].text) #LB spending\n",
    "        list_s.append(cells[9].text) #S spending\n",
    "        list_cb.append(cells[10].text) #CB spending\n",
    "\n",
    "    spending = pd.DataFrame({'Team': list_teams, 'QB': list_qb, 'RB/FB': list_rb, 'WR': list_wr, 'TE': list_te, 'OL': list_ol, 'DL': list_dl, 'LB': list_lb, 'S': list_s, 'CB': list_cb})\n",
    "    spending.set_index('Team', inplace=True)\n",
    "    spending = spending.applymap(lambda x: x[1:].replace(',', '')).astype('int64')\n",
    "    spending = spending.div(spending.sum(axis=1), axis=0)\n",
    "    spending = spending.reset_index()\n",
    "    spending['Team'] = spending['Team'].map(team_initial)\n",
    "    spending['Defense']= spending[['DL','LB','S','CB']].sum(axis=1)\n",
    "    spending['Year'] = year\n",
    "    return spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for scraping data for offense and defensive line data and small formatting changes\n",
    "def get_line_data(offense, year):\n",
    "    #Beautifulsoup to scrape\n",
    "    page = requests.get('https://www.footballoutsiders.com/stats/nfl/' + offense + '-line/' + str(year))\n",
    "    html = BeautifulSoup(page.text)\n",
    "    oline = pd.read_html(str(html.find('table')))[0]\n",
    "    #renamed columns that had the same name\n",
    "    if 'RUN BLOCKING' in oline.columns:    \n",
    "        oline.columns = oline.columns.droplevel()\n",
    "        cols = list(oline.columns)\n",
    "        cols[12] = \"Team_pass\"\n",
    "        cols[13] = \"Rank_pass\"\n",
    "        oline.columns = cols\n",
    "    else:\n",
    "        #Difference in how bf scrapes data depending on year so we had to reformat it for those cases\n",
    "        oline.columns = oline.iloc[1]\n",
    "        oline = oline.drop([0,1,18,19], axis = 0)\n",
    "        cols = list(oline.columns)\n",
    "        cols[0] = 'Rank'\n",
    "        cols[12] = \"Team_pass\"\n",
    "        cols[13] = \"Rank_pass\"\n",
    "        oline.columns = cols\n",
    "    oline['Year'] = year\n",
    "    return oline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for scraping qb data and small formatting changes\n",
    "def get_qb_data(year):\n",
    "    page = requests.get('https://www.footballoutsiders.com/stats/nfl/qb/' + str(year))\n",
    "    html = BeautifulSoup(page.text)\n",
    "    qb1 = pd.read_html(str(html.find_all('table')[0]))[0]\n",
    "    qb2 = pd.read_html(str(html.find_all('table')[1]))[0]\n",
    "    #Selected certain columns and combined multiple tables into one\n",
    "    if 'Player' in qb1.columns:\n",
    "        qb1 = qb1.drop(['Rk', 'Rk.1', 'Rk.2', 'Rk.3'], axis = 1)\n",
    "        qb = pd.concat([qb1, qb2], sort = False)\n",
    "    else:\n",
    "        qb1.columns = qb1.iloc[0]\n",
    "        qb1 = qb1.drop(['Rk'], axis = 1)\n",
    "        qb1 = qb1.drop([0], axis = 0)\n",
    "        qb2.columns = qb2.iloc[0]\n",
    "        qb2 = qb2.drop([0], axis = 0)\n",
    "        qb = pd.concat([qb1, qb2], sort = False)\n",
    "    qbr = pd.read_html(str(html.find_all('table')[2]))[0]\n",
    "    if 'Player' not in qbr.columns:\n",
    "        qbr.columns = qbr.iloc[0]\n",
    "    #dropped rows which duplicated column names\n",
    "    qb = qb[qb['Player'] != 'Player']\n",
    "    qbr = qbr[qbr['Player'] != 'Player']\n",
    "    qb['Year'] = year\n",
    "    qbr['Year'] = year\n",
    "    return qb, qbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scraping rb data and small formatting changes\n",
    "def get_rb_data(year):\n",
    "    page = requests.get('https://www.footballoutsiders.com/stats/nfl/rb/' + str(year))\n",
    "    html = BeautifulSoup(page.text)\n",
    "    rb1 = pd.read_html(str(html.find_all('table')[0]))[0]\n",
    "    rb2 = pd.read_html(str(html.find_all('table')[1]))[0]\n",
    "    #Selected certain columns and combined multiple tables into one\n",
    "    if 'Player' in rb1.columns:\n",
    "        rb1 = rb1.drop(['Rk', 'Rk.1', 'Rk.2', 'Rk.3'], axis = 1)\n",
    "        rb = pd.concat([rb1, rb2], sort = False)\n",
    "    else:\n",
    "        rb1.columns = rb1.iloc[0]\n",
    "        rb1 = rb1.drop(['Rk'], axis = 1)\n",
    "        rb1 = rb1.drop([0], axis = 0)\n",
    "        rb2.columns = rb2.iloc[0]\n",
    "        rb2 = rb2.drop([0], axis = 0)\n",
    "        rb = pd.concat([rb1, rb2], sort = False)\n",
    "    rbr1 = pd.read_html(str(html.find_all('table')[2]))[0]\n",
    "    rbr2 = pd.read_html(str(html.find_all('table')[3]))[0]\n",
    "    if 'Player' in rbr1.columns:\n",
    "        rbr1 = rbr1.drop(['Rk', 'Rk.1', 'Rk.2'], axis = 1)\n",
    "        rbr = pd.concat([rbr1, rbr2], sort = False)\n",
    "    else:\n",
    "        rbr1.columns = rbr1.iloc[0]\n",
    "        rbr1 = rbr1.drop(['Rk'], axis = 1)\n",
    "        rbr1 = rbr1.drop([0], axis = 0)\n",
    "        rbr2.columns = rbr2.iloc[0]\n",
    "        rbr2 = rbr2.drop([0], axis = 0)\n",
    "        rbr = pd.concat([rbr1, rbr2], sort = False)\n",
    "    #dropped rows which duplicated column names\n",
    "    rb = rb[rb['Player'] != 'Player']\n",
    "    rbr = rbr[rbr['Player'] != 'Player']\n",
    "    rb['Year'] = year\n",
    "    rbr['Year'] = year\n",
    "    return rb, rbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scraping te data and small formatting changes\n",
    "def get_te_data(year):\n",
    "    page = requests.get('https://www.footballoutsiders.com/stats/nfl/te/' + str(year))\n",
    "    html = BeautifulSoup(page.text)\n",
    "    te1 = pd.read_html(str(html.find_all('table')[0]))[0]\n",
    "    te2 = pd.read_html(str(html.find_all('table')[1]))[0]\n",
    "    if 'Player' in te1.columns:\n",
    "        te1 = te1.drop(['Rk', 'Rk.1', 'Rk.2'], axis = 1)\n",
    "        te = pd.concat([te1, te2], sort = False)\n",
    "    else:\n",
    "        te1.columns = te1.iloc[0]\n",
    "        te1 = te1.drop(['Rk'], axis = 1)\n",
    "        te1 = te1.drop([0], axis = 0)\n",
    "        te2.columns = te2.iloc[0]\n",
    "        te2 = te2.drop([0], axis = 0)\n",
    "        te = pd.concat([te1, te2], sort = False)\n",
    "    te = te[te['Player']!= 'Player']\n",
    "    te['Year'] = year\n",
    "    return te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scraping wr data and small formatting changes\n",
    "def get_wr_data(year):\n",
    "    #left out rushing due to infrequency\n",
    "    page = requests.get('https://www.footballoutsiders.com/stats/nfl/wr/' + str(year))\n",
    "    html = BeautifulSoup(page.text)\n",
    "    wr1 = pd.read_html(str(html.find_all('table')[0]))[0]\n",
    "    wr2 = pd.read_html(str(html.find_all('table')[1]))[0]\n",
    "    #Selected certain columns and combined multiple tables into one\n",
    "    if 'Player' in wr1.columns:\n",
    "        wr1 = wr1.drop(['Rk', 'Rk.1', 'Rk.2'], axis = 1)\n",
    "        wr = pd.concat([wr1, wr2], sort = False)\n",
    "    else:\n",
    "        wr1.columns = wr1.iloc[0]\n",
    "        wr1 = wr1.drop(['Rk'], axis = 1)\n",
    "        wr1 = wr1.drop([0], axis = 0)\n",
    "        wr2.columns = wr2.iloc[0]\n",
    "        wr2 = wr2.drop([0], axis = 0)\n",
    "        wr = pd.concat([wr1, wr2], sort = False)\n",
    "    wr = wr[wr['Player'] != 'Player']\n",
    "    wr['Year'] = year\n",
    "    return wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scraping team defense data and small formatting changes\n",
    "def get_def_data(year):\n",
    "    page = requests.get('https://www.footballoutsiders.com/stats/nfl/team-defense/' + str(year))\n",
    "    html = BeautifulSoup(page.text)\n",
    "    defense = pd.read_html(str(html.find_all('table')[0]))[0]\n",
    "    if 'TEAM' not in defense.columns:\n",
    "        defense = defense.fillna('RK')\n",
    "        defense = defense.drop([0], axis =0)\n",
    "        defense.columns = list(defense.iloc[0])\n",
    "        defense = defense[defense['TEAM']!= 'TEAM']\n",
    "        defense = defense.reset_index(drop=True)\n",
    "    defense = defense[defense['TEAM']!= 'TEAM']\n",
    "    defense['Year'] = year\n",
    "    return defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape spending data\n",
    "team_spending_2019 = get_spending_data_by_year('https://overthecap.com/positional-spending', 2019)\n",
    "team_spending_2018 = get_spending_data_by_year('https://overthecap.com/positional-spending', 2018)\n",
    "team_spending_2017 = get_spending_data_by_year('https://overthecap.com/positional-spending', 2017)\n",
    "team_spending_2016 = get_spending_data_by_year('https://overthecap.com/positional-spending', 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape ol data\n",
    "oline_data_2019 = get_line_data('offensive', 2019)\n",
    "oline_data_2018 = get_line_data('offensive', 2018)\n",
    "oline_data_2017 = get_line_data('offensive', 2017)\n",
    "oline_data_2016 = get_line_data('offensive', 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape dline data\n",
    "dline_data_2019 = get_line_data('defensive', 2019)\n",
    "dline_data_2018 = get_line_data('defensive', 2018)\n",
    "dline_data_2017 = get_line_data('defensive', 2017)\n",
    "dline_data_2016 = get_line_data('defensive', 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape qb data\n",
    "qb_passing_data_2019, qb_rushing_data_2019 = get_qb_data(2019)\n",
    "qb_passing_data_2018, qb_rushing_data_2018 = get_qb_data(2018)\n",
    "qb_passing_data_2017, qb_rushing_data_2017 = get_qb_data(2017)\n",
    "qb_passing_data_2016, qb_rushing_data_2016 = get_qb_data(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape rb data\n",
    "rb_rushing_data_2019, rb_receiving_data_2019 = get_rb_data(2019)\n",
    "rb_rushing_data_2018, rb_receiving_data_2018 = get_rb_data(2018)\n",
    "rb_rushing_data_2017, rb_receiving_data_2017 = get_rb_data(2017)\n",
    "rb_rushing_data_2016, rb_receiving_data_2016 = get_rb_data(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape te data\n",
    "te_data_2019 = get_te_data(2019)\n",
    "te_data_2018 = get_te_data(2018)\n",
    "te_data_2017 = get_te_data(2017)\n",
    "te_data_2016 = get_te_data(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape wr data\n",
    "wr_data_2019 = get_wr_data(2019)\n",
    "wr_data_2018 = get_wr_data(2018)\n",
    "wr_data_2017 = get_wr_data(2017)\n",
    "wr_data_2016 = get_wr_data(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape team defense data\n",
    "team_def_data_2019 = get_def_data(2019)\n",
    "team_def_data_2018 = get_def_data(2018)\n",
    "team_def_data_2017 = get_def_data(2017)\n",
    "team_def_data_2016 = get_def_data(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We had to do minimal cleaning, because there was no missing data from the tables that we scraped, and it was already tidy. We had a few cases of players being traded mid-season; we handled that by splitting the performance metrics proportionally between the teams that they played for based on games played while with each team. We also had to drop some position groups, due to the lack of a reasonable metric by which to measure their performance by. Lastly, we needed to fix team name abbreviations to that we would have a consistent set of abbreviations to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset all indices for player data\n",
    "qb_passing_data_2019.reset_index(inplace=True)\n",
    "qb_passing_data_2018.reset_index(inplace=True)\n",
    "qb_passing_data_2017.reset_index(inplace=True)\n",
    "qb_passing_data_2016.reset_index(inplace=True)\n",
    "\n",
    "rb_rushing_data_2019.reset_index(inplace=True)\n",
    "rb_rushing_data_2018.reset_index(inplace=True)\n",
    "rb_rushing_data_2017.reset_index(inplace=True)\n",
    "rb_rushing_data_2016.reset_index(inplace=True)\n",
    "rb_receiving_data_2019.reset_index(inplace=True)\n",
    "rb_receiving_data_2018.reset_index(inplace=True)\n",
    "rb_receiving_data_2017.reset_index(inplace=True)\n",
    "rb_receiving_data_2016.reset_index(inplace=True)\n",
    "\n",
    "te_data_2019.reset_index(inplace=True)\n",
    "te_data_2018.reset_index(inplace=True)\n",
    "te_data_2017.reset_index(inplace=True)\n",
    "te_data_2016.reset_index(inplace=True)\n",
    "\n",
    "wr_data_2019.reset_index(inplace=True)\n",
    "wr_data_2018.reset_index(inplace=True)\n",
    "wr_data_2017.reset_index(inplace=True)\n",
    "wr_data_2016.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for spliting data listed as 2TM weighted by proportion of games played per team\n",
    "def split_stats(index, stat_name, div1, div2, team1, team2, dataset):\n",
    "    dataset[stat_name] = dataset[stat_name].astype(float)\n",
    "    stat = dataset.at[index, stat_name]\n",
    "    playerName = dataset.at[index, 'Player']\n",
    "    \n",
    "    row1 = dataset[dataset['Player']==playerName].replace(['2TM', stat], [team1, stat * div1/(div1+div2)])\n",
    "    row2 = dataset[dataset['Player']==playerName].replace(['2TM', stat], [team2, stat * div2/(div1+div2)])\n",
    "    return dataset.append([row1, row2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No easy way to do this other than hard coding results found from pro-football-reference.com\n",
    "rb_rushing_data_2019 = split_stats(4, 'EYds', 6, 10, 'MIA', 'ARI', rb_rushing_data_2019)\n",
    "\n",
    "rb_rushing_data_2018 = split_stats(35, 'EYds', 6, 8, 'CLE', 'JAX', rb_rushing_data_2018)\n",
    "rb_rushing_data_2018 = split_stats(47, 'EYds', 9, 2, 'CAR', 'LAR', rb_rushing_data_2018)\n",
    "rb_rushing_data_2018 = split_stats(51, 'EYds', 10, 2, 'WAS', 'GB', rb_rushing_data_2018)\n",
    "rb_rushing_data_2018 = split_stats(66, 'EYds', 7, 6, 'GB', 'BAL', rb_rushing_data_2018)\n",
    "\n",
    "rb_rushing_data_2017 = split_stats(26, 'EYds', 7, 7, 'MIA', 'PHI', rb_rushing_data_2017)\n",
    "rb_rushing_data_2017 = split_stats(45, 'EYds', 4, 6, 'NOR', 'ARI', rb_rushing_data_2017)\n",
    "rb_rushing_data_2017 = split_stats(80, 'EYds', 3, 6, 'NYJ', 'BUF', rb_rushing_data_2017)\n",
    "rb_rushing_data_2017 = split_stats(82, 'EYds', 8, 4, 'ARI', 'HOU', rb_rushing_data_2017)\n",
    "\n",
    "rb_rushing_data_2016 = split_stats(20, 'EYds', 9, 6, 'SEA', 'GB', rb_rushing_data_2016)\n",
    "rb_rushing_data_2016 = split_stats(90, 'EYds', 5, 3, 'MIN', 'LAC', rb_rushing_data_2016)\n",
    "\n",
    "rb_receiving_data_2019 = split_stats(29, 'EYds', 6, 10, 'MIA', 'ARI', rb_receiving_data_2019)\n",
    "\n",
    "rb_receiving_data_2018 = split_stats(39, 'EYds', 7, 6, 'GB', 'BAL', rb_receiving_data_2018)\n",
    "rb_receiving_data_2018 = split_stats(82, 'EYds', 10, 2, 'WAS', 'GB', rb_receiving_data_2018)\n",
    "rb_receiving_data_2018 = split_stats(87, 'EYds', 6, 8, 'CLE', 'JAX', rb_receiving_data_2018)\n",
    "\n",
    "rb_receiving_data_2017 = split_stats(19, 'EYds', 8, 4, 'ARI', 'HOU', rb_receiving_data_2017) #a ellington\n",
    "rb_receiving_data_2017 = split_stats(52, 'EYds', 7, 7, 'MIA', 'PHI', rb_receiving_data_2017) #ajayi\n",
    "rb_receiving_data_2017 = split_stats(72, 'EYds', 3, 6, 'NYJ', 'BUF', rb_receiving_data_2017) #cadet\n",
    "rb_receiving_data_2017 = split_stats(86, 'EYds', 4, 6, 'NOR', 'ARI', rb_receiving_data_2017) #ap\n",
    "\n",
    "rb_receiving_data_2016 = split_stats(51, 'EYds', 9, 6, 'SEA', 'GB', rb_receiving_data_2016)\n",
    "rb_receiving_data_2016 = split_stats(75, 'EYds', 5, 3, 'MIN', 'LAC', rb_receiving_data_2016)\n",
    "rb_receiving_data_2016 = split_stats(87, 'EYds', 2, 4, 'SEA', 'NYJ', rb_receiving_data_2016)\n",
    "\n",
    "qb_passing_data_2017 = qb_passing_data_2017.replace(['2TM'], ['SF'])\n",
    "\n",
    "te_data_2019 = split_stats(55, 'EYds', 2, 3, 'NO', 'ARI', te_data_2019)\n",
    "te_data_2019 = split_stats(61, 'EYds', 3, 13, 'SEA', 'PIT', te_data_2019)\n",
    "te_data_2019 = split_stats(72, 'EYds', 7, 5, 'MIA', 'JAX', te_data_2019)\n",
    "\n",
    "te_data_2017 = split_stats(28, 'EYds', 7, 2, 'GB', 'NE', te_data_2017)\n",
    "te_data_2017 = split_stats(49, 'EYds', 9, 2, 'DEN', 'MIA', te_data_2017)\n",
    "te_data_2017 = split_stats(81, 'EYds', 11, 4, 'KC', 'IND', te_data_2017)\n",
    "\n",
    "wr_data_2019 = split_stats(20, 'EYds', 7, 9, 'DEN', 'SF', wr_data_2019)\n",
    "wr_data_2019 = split_stats(72, 'EYds', 7, 8, 'ATL', 'NE', wr_data_2019)\n",
    "wr_data_2019 = split_stats(96, 'EYds', 6, 5, 'NE', 'SEA', wr_data_2019)\n",
    "wr_data_2019 = split_stats(101, 'EYds', 7, 6, 'IND', 'PIT', wr_data_2019)\n",
    "wr_data_2019 = split_stats(123, 'EYds', 4, 3, 'LAC', 'IND', wr_data_2019)\n",
    "wr_data_2019 = split_stats(127, 'EYds', 2, 9, 'GB', 'OAK', wr_data_2019)\n",
    "wr_data_2019 = split_stats(150, 'EYds', 12, 4, 'PHI', 'MIA', wr_data_2019)\n",
    "wr_data_2019 = split_stats(163, 'EYds', 5, 10, 'BUF', 'OAK', wr_data_2019)\n",
    "\n",
    "wr_data_2018 = split_stats(17, 'EYds', 1, 11, 'CLE', 'NE', wr_data_2018)\n",
    "wr_data_2018 = split_stats(19, 'EYds', 6, 9, 'OAK', 'DAL', wr_data_2018)\n",
    "wr_data_2018 = split_stats(42, 'EYds', 8, 7, 'DEN', 'HOU', wr_data_2018)\n",
    "wr_data_2018 = split_stats(78, 'EYds', 12, 3, 'BUF', 'KC', wr_data_2018)\n",
    "wr_data_2018 = split_stats(83, 'EYds', 7, 8, 'DET', 'PHI', wr_data_2018)\n",
    "wr_data_2018 = split_stats(102, 'EYds', 6, 2, 'NYJ', 'BUF', wr_data_2018)\n",
    "wr_data_2018 = split_stats(110, 'EYds', 7, 7, 'PHI', 'HOU', wr_data_2018)\n",
    "wr_data_2018 = split_stats(117, 'EYds', 2, 6, 'DAL', 'MIA', wr_data_2018)\n",
    "wr_data_2018 = split_stats(124, 'EYds', 12, 3, 'BUF', 'DEN', wr_data_2018)\n",
    "wr_data_2018 = split_stats(146, 'EYds', 8, 5, 'DAL', 'BUF', wr_data_2018)\n",
    "wr_data_2018 = split_stats(157, 'EYds', 3, 4, 'HOU', 'DET', wr_data_2018)\n",
    "\n",
    "wr_data_2017 = split_stats(35, 'EYds', 8, 6, 'CAR', 'BUF', wr_data_2017)\n",
    "wr_data_2017 = split_stats(55, 'EYds', 5, 11, 'CHI', 'BUF', wr_data_2017)\n",
    "wr_data_2017 = split_stats(98, 'EYds', 4, 8, 'LAC', 'CHI', wr_data_2017)\n",
    "wr_data_2017 = split_stats(135, 'EYds', 9, 3, 'CLE', 'NE', wr_data_2017)\n",
    "wr_data_2017 = split_stats(149, 'EYds', 4, 9, 'BUF', 'CAR', wr_data_2017)\n",
    "\n",
    "wr_data_2016 = split_stats(66, 'EYds', 13, 2, 'ARI', 'NE', wr_data_2016)\n",
    "wr_data_2016 = split_stats(138, 'EYds', 7, 3, 'PHI', 'TB', wr_data_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#playoff files with boolean values for whether each team made the playoffs in a particular year\n",
    "playoffs = pd.read_csv('playoffs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned playoff data so it can join with the rest of data\n",
    "playoffs['Team'] = playoffs['Tm'].str.split()\n",
    "playoffs['Team'] = playoffs['Team'].str[-1].map(team_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "We dropped/combined unused positions and standardized team name abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which groups qb data by team. Performance per team determined by QBR weighted by proportion of plays\n",
    "def group_teams_qb(df):\n",
    "    df['QBR'] = df['QBR'].astype(float)\n",
    "    df['Pass'] = df['Pass'].astype(int)\n",
    "    df['Weighted QBR'] = df.apply(lambda x: x['QBR'] * x['Pass']/ df.groupby('Team')['Pass'].sum()[x['Team']], axis=1)\n",
    "    result = pd.DataFrame(df.groupby('Team')['Weighted QBR'].sum())\n",
    "    result['Year'] = int(df['Year'].mean())\n",
    "    result['Weighted QBR'] = stats.zscore(result['Weighted QBR'])\n",
    "    result = result.rename(columns={'Weighted QBR': 'QB Score'})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which groups rb by team, summing EYds for every running backs rushing and receiving totals per team\n",
    "def group_teams_rb(df1, df2):\n",
    "    df1['EYds'] = df1['EYds'].astype(int)\n",
    "    df2['EYds'] = df2['EYds'].astype(int)\n",
    "    rush = df1.groupby('Team')['EYds'].sum()\n",
    "    rec = df2.groupby('Team')['EYds'].sum()\n",
    "    result = pd.DataFrame(rec+rush).groupby('Team')['EYds'].sum()\n",
    "    result = pd.DataFrame(result)\n",
    "    result['Year'] = int(df1['Year'].mean())\n",
    "    result['EYds'] = stats.zscore(result['EYds'])\n",
    "    result = result.rename(columns={'EYds': 'RB Score'})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which groups wr by team, summing EYds for each team\n",
    "def group_teams_wr(df):\n",
    "    df['EYds'] = df['EYds'].astype(int)\n",
    "    result = df.groupby('Team')['EYds'].sum()\n",
    "    result = pd.DataFrame(result)\n",
    "    result['Year'] = int(df['Year'].mean())\n",
    "    result['EYds'] = stats.zscore(result['EYds'])\n",
    "    result = result.rename(columns={'EYds': 'WR Score'})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which groups wte by team, summing EYds for each team\n",
    "def group_teams_te(df):\n",
    "    df['EYds'] = df['EYds'].astype(int)\n",
    "    result = df.groupby('Team')['EYds'].sum()\n",
    "    result = pd.DataFrame(result)\n",
    "    result['Year'] = int(df['Year'].mean())\n",
    "    result['EYds'] = stats.zscore(result['EYds'])\n",
    "    result = result.rename(columns={'EYds': 'TE Score'})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which aggregrates the most important lineman stats into one average total,\n",
    "#weighting performance for running and passing\n",
    "def group_teams_oline(df):\n",
    "    df = df[df['Team'] != 'NFL']\n",
    "    df_ordered = df[['Team','Adj. Line  Yards']].sort_values('Team')\n",
    "    df_ordered2 = df[['Team_pass','Adjusted  Sack Rate']].sort_values('Team_pass')['Adjusted  Sack Rate']\n",
    "    df_ordered['Adjusted  Sack Rate'] = list(df_ordered2)\n",
    "    df_ordered['Adj. Line  Yards'] = df_ordered['Adj. Line  Yards'].astype(float)\n",
    "    df_ordered['alyz'] = stats.zscore(df_ordered['Adj. Line  Yards'])\n",
    "    df_ordered['Adjusted  Sack Rate'] = df_ordered['Adjusted  Sack Rate'].str[:-1].astype(float)\n",
    "    df_ordered['asrz'] = stats.zscore(df_ordered['Adjusted  Sack Rate'])\n",
    "    result = (df_ordered['alyz'] - df_ordered['asrz']) / 2\n",
    "    result = pd.DataFrame(result, columns = ['OL Score'])\n",
    "    result = result.set_index(df_ordered['Team'])\n",
    "    result['Year'] = result['Year'] = int(df['Year'].mean())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which aggregrates the most important lineman stats into one average total,\n",
    "#weighting performance for running and passing\n",
    "def group_teams_dline(df):\n",
    "    df = df[df['Team'] != 'NFL']\n",
    "    df_ordered = df[['Team','Adj. Line  Yards']].sort_values('Team')\n",
    "    df_ordered2 = df[['Team_pass','Adjusted  Sack Rate']].sort_values('Team_pass')['Adjusted  Sack Rate']\n",
    "    df_ordered['Adjusted  Sack Rate'] = list(df_ordered2)\n",
    "    df_ordered['Adj. Line  Yards'] = df_ordered['Adj. Line  Yards'].astype(float)\n",
    "    df_ordered['alyz'] = stats.zscore(df_ordered['Adj. Line  Yards'])\n",
    "    df_ordered['Adjusted  Sack Rate'] = df_ordered['Adjusted  Sack Rate'].str[:-1].astype(float)\n",
    "    df_ordered['asrz'] = stats.zscore(df_ordered['Adjusted  Sack Rate'])\n",
    "    result = (df_ordered['asrz'] - df_ordered['alyz']) / 2\n",
    "    result = pd.DataFrame(result, columns = ['DL Score'])\n",
    "    result = result.set_index(df_ordered['Team'])\n",
    "    result['Year'] = result['Year'] = int(df['Year'].mean())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected wei defense stats to use for analysis\n",
    "def group_defense(df):\n",
    "    if 'WEI.DEFENSE' not in df.columns:\n",
    "        df = df.rename(columns={'WEI.  DEFENSE': 'WEI.DEFENSE'})\n",
    "    df['Defense Score'] = df['WEI.DEFENSE'].str[:-1].astype(float)\n",
    "    df['Defense Score'] = -stats.zscore(df['Defense Score'])\n",
    "    result = df[['TEAM', 'Defense Score']].rename(columns = {'TEAM': 'Team'})\n",
    "    result = result.set_index('Team')\n",
    "    result['Year'] = int(df['Year'].mean())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran all grouping functions and combined all years into one table\n",
    "total_spending = pd.concat([team_spending_2019, team_spending_2018, team_spending_2017, team_spending_2016])\n",
    "qb_scores = pd.concat([group_teams_qb(qb_passing_data_2019), group_teams_qb(qb_passing_data_2018), group_teams_qb(qb_passing_data_2017), group_teams_qb(qb_passing_data_2016)])\n",
    "rb_scores = pd.concat([group_teams_rb(rb_rushing_data_2019, rb_receiving_data_2019), group_teams_rb(rb_rushing_data_2018, rb_receiving_data_2018), group_teams_rb(rb_rushing_data_2017, rb_receiving_data_2017), group_teams_rb(rb_rushing_data_2016, rb_receiving_data_2016)])\n",
    "wr_scores = pd.concat([group_teams_wr(wr_data_2019), group_teams_wr(wr_data_2018), group_teams_wr(wr_data_2017), group_teams_wr(wr_data_2016)])\n",
    "te_scores = pd.concat([group_teams_te(wr_data_2019), group_teams_te(wr_data_2018), group_teams_te(te_data_2017), group_teams_te(te_data_2016)])\n",
    "ol_scores = pd.concat([group_teams_oline(oline_data_2019), group_teams_oline(oline_data_2018),group_teams_oline(oline_data_2017),group_teams_oline(oline_data_2016),])\n",
    "dl_scores = pd.concat([group_teams_dline(dline_data_2019), group_teams_dline(dline_data_2018),group_teams_dline(dline_data_2017),group_teams_dline(dline_data_2016),])\n",
    "defense_scores = pd.concat([group_defense(team_def_data_2019), group_defense(team_def_data_2018), group_defense(team_def_data_2017), group_defense(team_def_data_2016)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all tables on team and year and combined into one full table with all spending and performance metrics data\n",
    "df = pd.merge(qb_scores.reset_index(), rb_scores.reset_index(), on=['Team', 'Year'])\n",
    "df = pd.merge(df, wr_scores.reset_index(), on=['Team', 'Year'])\n",
    "df = pd.merge(df, te_scores.reset_index(), on=['Team', 'Year'])\n",
    "df = pd.merge(df, ol_scores.reset_index(), on=['Team', 'Year'])\n",
    "df = pd.merge(df, dl_scores.reset_index(), on=['Team', 'Year'])\n",
    "df = pd.merge(df, defense_scores.reset_index(), on=['Team', 'Year'])\n",
    "df = df.replace(['LARM', 'LARC', 'LACH', 'SD', 'JAC'], ['LAR', 'LAC', 'LAC', 'LAC', 'JAX'])\n",
    "df = pd.merge(total_spending, df, on=['Team', 'Year'])\n",
    "cols = ['Year', 'Team', 'QB', 'QB Score', 'RB/FB', 'RB Score', 'WR', 'WR Score', 'TE', 'TE Score', 'OL', 'OL Score', 'DL', 'DL Score', 'Defense', 'Defense Score']\n",
    "df = df[cols]\n",
    "df = pd.merge(df, playoffs[['Team', 'Year', 'Playoffs']], on =['Team', 'Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "We first made histograms of all the salaries for each position over the past 4 years for each position using pandas histogram package, which allows us to get a general idea of the distribution of salaries for each position. Looking at the graphs below, we see that there is most discrepancy of salaries in postions like safety, offensive line, and tight ends, which we believe will show the most statistical signifigance if the higher paid player preforms better statistically, or even the lower paid player preform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample of final dataframe\n",
    "team_spending_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2019 = team_spending_2019.drop('Year', axis=1).hist(bins = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_2018 = team_spending_2018.drop('Year', axis=1).hist(bins = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_2017 = team_spending_2017.drop('Year', axis=1).hist(bins = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_2016 = team_spending_2016.drop('Year', axis=1).hist(bins = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Across Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =sns.distplot(df['QB'], bins=10);\n",
    "ax.set_title('QB Spending distribution')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df['WR'], bins=10);\n",
    "ax.set_title('WR Spending distribution')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df['TE'], bins=10);\n",
    "ax.set_title('TE Spending distribution')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df['DL'], bins=10);\n",
    "ax.set_title('DL Spending distribution')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(df['OL'], bins=10);\n",
    "ax.set_title('OL Spending distribution')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =sns.distplot(df['Defense'], bins=10);\n",
    "ax.set_title('Defense Spending distribution')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions for Spending on Positions:\n",
    "\n",
    "QB - Not Normal,\n",
    "WR - Normal,\n",
    "TE - Right Skewed,\n",
    "DL - Not Normal,\n",
    "OL - Normal,\n",
    "Defense - Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = team_spending_2019['CB'].sort_values().plot(kind = 'bar')\n",
    "ax.set_title('CB Spending Across Teams')\n",
    "ax.set_xlabel('Teams')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = team_spending_2019['S'].sort_values().plot(kind = 'bar')\n",
    "ax.set_title('S Spending Across Teams')\n",
    "ax.set_xlabel('Teams')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = team_spending_2019['OL'].sort_values().plot(kind = 'bar')\n",
    "ax.set_title('OL Spending Across Teams')\n",
    "ax.set_xlabel('Teams')\n",
    "ax.set_ylabel('Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QB scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['QB'], y=df['QB Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('QBR zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['RB/FB'], y=df['RB Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('RB EYds zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WR scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['WR'], y=df['WR Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('WR EYds zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TE scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['TE'], y=df['TE Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('TE EYds zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OL scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['OL'], y=df['OL Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('OL Aggregate zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['DL'], y=df['DL Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('DL Aggregate zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defense scatter plot. Yellow mean that team went to the playoffs\n",
    "plt.scatter(x=df['Defense'], y=df['Defense Score'], c=df['Playoffs'])\n",
    "plt.xlabel('Proportion of Cap')\n",
    "plt.ylabel('Defense Aggregate zscore by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation for all position groups\n",
    "ol_r = stats.pearsonr(df['OL'], df['OL Score'])[0]\n",
    "qb_r = stats.pearsonr(df['QB'], df['QB Score'])[0]\n",
    "rb_r = stats.pearsonr(df['RB/FB'], df['RB Score'])[0]\n",
    "wr_r = stats.pearsonr(df['WR'], df['WR Score'])[0]\n",
    "te_r = stats.pearsonr(df['TE'], df['TE Score'])[0]\n",
    "dl_r = stats.pearsonr(df['DL'], df['DL Score'])[0]\n",
    "def_r = stats.pearsonr(df['Defense'], df['Defense Score'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Z Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for fisher z transformation and z-test on said transformation\n",
    "def fisher_dif(r1, r2):\n",
    "    z1 = (1/2)*(np.log(1+r1) - np.log(1-r1))\n",
    "    z2 = (1/2)*(np.log(1+r2) - np.log(1-r2))\n",
    "    s = np.sqrt((1/125) + (1/125))\n",
    "    z = (z1-z2) / s\n",
    "    p_value = stats.norm.sf(abs(z))\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = [qb_r, rb_r, wr_r, te_r, ol_r, dl_r, def_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrix to claculate difference between every position group\n",
    "cols = []\n",
    "for i in range(len(rs)):\n",
    "    row = []\n",
    "    for j in range(len(rs)):\n",
    "        row.append(fisher_dif(rs[i], rs[j]))\n",
    "    cols.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p-value matrix\n",
    "names = ['QB', 'RB', 'WR', 'TE', 'OL', 'DL', 'DEF']\n",
    "pd.DataFrame(cols, columns = names, index = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have permission to utilize our data because sports players' statistics in sports league such as NFL are not copyrightable. Our data are published in the public domain, therefore we do not expect any privacy concerns or terms of use we need to comply. The potential biases in our datasets may include referee bias and human error when determining the status of the plays and calculating the scores. There are also personal bias like racial bias that affect the opportunities that a player can play in the field to update their performance statistics. Our analyses may cause potential shift in opinions on the worth of players, in which affect their reputation within the sports league. To handle the issues we have identified, we will make players' name anonymous. We will clean and verify our datasets. In addition, we will consider extraneous variables and not make casual conclusions when analyzing our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION\n",
    "\n",
    "Looking at the scatterplot and the correlation coefficients for quarterbacks, we can't make out any signifigance between investing in a better quartback and the quarterback performing better (Line of best fit is pretty flat). We see a similar trend with the running back, defensive line, and defensive (S, CB, LB, DL) categories where the line of best fit is pretty flat. This means that spending more money didn't necessarily result in a better player.\n",
    "\n",
    "We were surprised to see that the wide receiver scatterplot had the most positive line of trend, meaning that investing more money into a player of that position, gave teams a player that performed better. Similarly, the offensive line has a postive trend. Also, it's important to note that the running back position has a negative coefficient meaning that spending didn't necessarily mean a better player. \n",
    "\n",
    "Also, another signifigant pattern we see with the data is that teams that had a quarterback that performs well were more likely to get into the playoffs. We see this by looking at the yellow points in the quarterback data set.\n",
    "\n",
    "We used fisher's z transformation to turn the correlation coefficients into a z score, in order to run a t-test to determine whether the difference between correlation coefficients is signifigant. We found that the only signifigant pairings were the ones (meaning a p score less than .05) that involved the wide reciever and offensive line positions meaning that we reject the null hypothesis (investing more into one position will get you a better player). For others, there isn't much statistical evidence to reject the null hypothesis that investing more into one player will get you a better player.\n",
    "\n",
    "LIMITIATIONS\n",
    "\n",
    "1) There are no standard metric to \"score\" a player's performance for some positions, and as a result, we had to do things like combining positions like safety, and corneback as defense.\n",
    "\n",
    "2) The game of football changes from year to year and as a result scoring a player's performance is quite hard. Because of this, we had to do things like normalize the perfomances each year. Also salary cap changes every year so players can get paid more as years go by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brandon did a lot of the work with data analysis. Vincent mainly focused on exploratory data analysis and creating data visualizations. Joseph was mainly concerned with scraping and cleaning data. Vicki helped coordinate and organize our team's entire effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
